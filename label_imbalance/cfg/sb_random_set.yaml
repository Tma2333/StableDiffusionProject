exp_name: CIFAR10-SDRandom
version: 5
seed: 69

training:
  batch_size: 256
  # train loader
  train_loader_worker: 8
  eval_loader_worker: 8
  #optimizer
  optimizer: "SGD"
  optimizer_cfg:
    lr: 0.1
    weight_decay: 0.0005
    momentum: 0.9
  scheduler: "Cosine"
  warm_up_epoch: 5
  trainer:
    # GPU config
    gpus: [4]
    strategy: ddp
    unused_params: True
    # Logging config
    save_dir: /deep2/u/yma42/files/results/cs230
    # Callbacks
    save_top_k: 5 # checkpointing
    monitor_metric: Val/epoch_avg_accuracy
    monitor_mode: max
    patience: 20 # early stop
    # Misc
    gradient_clip_val: 0.5
    limit_train_batches: 1.0
    enable_model_summary: False
    max_epochs: 100

dataset:
  train_dataset: CIFAR10StableDiffusionDataset
  train_args:
    base_path: /deep2/u/yma42/StableDiffusionProject/label_imbalance/data/cifar-10-batches-py
    sb_path: /deep2/u/yma42/StableDiffusionProject/label_imbalance/data/sb_randm_sample.npy
    is_train: True
    standardize: True
    target_cls: 3
  eval_dataset: CIFAR10FullDataset
  eval_args:
    base_path: '/deep2/u/yma42/StableDiffusionProject/label_imbalance/data/cifar-10-batches-py'
    is_train: False
    standardize: True
  

models:
  # place holder
  type: resnet18
  pretrained: False

